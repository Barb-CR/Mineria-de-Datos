{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ac0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "data = df.sort_values(\"title\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50727cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>usability</th>\n",
       "      <th>num_of_files</th>\n",
       "      <th>types_of_files</th>\n",
       "      <th>files_size</th>\n",
       "      <th>vote_counts</th>\n",
       "      <th>medal</th>\n",
       "      <th>url_reference</th>\n",
       "      <th>keywords</th>\n",
       "      <th>num_of_columns</th>\n",
       "      <th>views</th>\n",
       "      <th>downloads</th>\n",
       "      <th>download_per_view</th>\n",
       "      <th>date_created</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>üìà Stock Market Tweet | Sentiment Analysis lexi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>57 MB</td>\n",
       "      <td>14</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/utkarshxy/stock-markettweets-lexicon-data</td>\n",
       "      <td>business,earth and nature,computer science,int...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>12/13/2020</td>\n",
       "      <td>01/04/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>üêüüêüüêüFish Species Image Data</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13233.0</td>\n",
       "      <td>other</td>\n",
       "      <td>1 GB</td>\n",
       "      <td>14</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/sripaadsrinivasan/fish-species-image-data</td>\n",
       "      <td>earth and nature,image data,animals,environmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11/09/2020</td>\n",
       "      <td>11/09/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>üèÜ Food Nutrition Information summary</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2 KB</td>\n",
       "      <td>12</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/lazycoder00/-nutritionalfacts-fruit-vegetable...</td>\n",
       "      <td>business,health,food,nutrition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>09/05/2020</td>\n",
       "      <td>09/05/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>üåäIndia Floods Inventoryüåä</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>54 KB</td>\n",
       "      <td>3</td>\n",
       "      <td>No_Medal</td>\n",
       "      <td>/aditya2803/india-floods-inventory</td>\n",
       "      <td>earth and nature,data visualization,explorator...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>01/06/2021</td>\n",
       "      <td>01/06/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>üáÆüá≥ NIFTY TOP 10 COMPANY  Historical data</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>260 KB</td>\n",
       "      <td>5</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/prokaggler/-nifty-top-10-company-historical-data</td>\n",
       "      <td>business,finance,investing,banking</td>\n",
       "      <td>15.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12/19/2020</td>\n",
       "      <td>12/19/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>Bag of Words Meets Bags of Popcorn :)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>other, CSV</td>\n",
       "      <td>52 MB</td>\n",
       "      <td>7</td>\n",
       "      <td>No_Medal</td>\n",
       "      <td>/rajathmc/bag-of-words-meets-bags-of-popcorn-</td>\n",
       "      <td>psychology</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2/13/2018</td>\n",
       "      <td>2/13/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>Allegheny County Property Sale Transactions</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>10 MB</td>\n",
       "      <td>3</td>\n",
       "      <td>No_Medal</td>\n",
       "      <td>/ashkhagan/allegheny-county-property-sale-tran...</td>\n",
       "      <td>real estate,housing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12/13/2020</td>\n",
       "      <td>12/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Air pressure system failures in Scania trucks</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CSV, other</td>\n",
       "      <td>36 MB</td>\n",
       "      <td>124</td>\n",
       "      <td>Silver</td>\n",
       "      <td>/uciml/aps-failure-at-scania-trucks-data-set</td>\n",
       "      <td>business,automobiles and vehicles,religion and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45875.0</td>\n",
       "      <td>4086.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2/16/2018</td>\n",
       "      <td>2/19/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Air Quality Data Set</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>248 KB</td>\n",
       "      <td>7</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/fedesoriano/air-quality-data-set</td>\n",
       "      <td>business,earth and nature,health,environment,w...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12/24/2020</td>\n",
       "      <td>12/24/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>Logistic regression To predict heart disease</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CSV</td>\n",
       "      <td>58 KB</td>\n",
       "      <td>171</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>/dileep070/heart-disease-prediction-using-logi...</td>\n",
       "      <td>health,health conditions,heart conditions,heal...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70970.0</td>\n",
       "      <td>9707.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>06/07/2019</td>\n",
       "      <td>06/07/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5717 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  usability  \\\n",
       "2770  üìà Stock Market Tweet | Sentiment Analysis lexi...       10.0   \n",
       "3646                         üêüüêüüêüFish Species Image Data       10.0   \n",
       "4845               üèÜ Food Nutrition Information summary        8.8   \n",
       "2790                           üåäIndia Floods Inventoryüåä       10.0   \n",
       "3565           üáÆüá≥ NIFTY TOP 10 COMPANY  Historical data        7.6   \n",
       "...                                                 ...        ...   \n",
       "5506              Bag of Words Meets Bags of Popcorn :)        7.1   \n",
       "5096       Allegheny County Property Sale Transactions        10.0   \n",
       "853       Air pressure system failures in Scania trucks        7.6   \n",
       "2846                               Air Quality Data Set       10.0   \n",
       "3008       Logistic regression To predict heart disease        7.1   \n",
       "\n",
       "      num_of_files types_of_files files_size  vote_counts     medal  \\\n",
       "2770           2.0            CSV     57 MB            14    Bronze   \n",
       "3646       13233.0          other      1 GB            14    Bronze   \n",
       "4845           1.0            CSV       2 KB           12    Bronze   \n",
       "2790           1.0            CSV     54 KB             3  No_Medal   \n",
       "3565          11.0            CSV     260 KB            5    Bronze   \n",
       "...            ...            ...        ...          ...       ...   \n",
       "5506           4.0     other, CSV      52 MB            7  No_Medal   \n",
       "5096           3.0            CSV     10 MB             3  No_Medal   \n",
       "853            5.0     CSV, other      36 MB          124    Silver   \n",
       "2846           1.0            CSV    248 KB             7    Bronze   \n",
       "3008           1.0            CSV      58 KB          171    Bronze   \n",
       "\n",
       "                                          url_reference  \\\n",
       "2770         /utkarshxy/stock-markettweets-lexicon-data   \n",
       "3646         /sripaadsrinivasan/fish-species-image-data   \n",
       "4845  /lazycoder00/-nutritionalfacts-fruit-vegetable...   \n",
       "2790                 /aditya2803/india-floods-inventory   \n",
       "3565  /prokaggler/-nifty-top-10-company-historical-data   \n",
       "...                                                 ...   \n",
       "5506      /rajathmc/bag-of-words-meets-bags-of-popcorn-   \n",
       "5096  /ashkhagan/allegheny-county-property-sale-tran...   \n",
       "853        /uciml/aps-failure-at-scania-trucks-data-set   \n",
       "2846                  /fedesoriano/air-quality-data-set   \n",
       "3008  /dileep070/heart-disease-prediction-using-logi...   \n",
       "\n",
       "                                               keywords  num_of_columns  \\\n",
       "2770  business,earth and nature,computer science,int...             4.0   \n",
       "3646  earth and nature,image data,animals,environmen...             NaN   \n",
       "4845                     business,health,food,nutrition             NaN   \n",
       "2790  earth and nature,data visualization,explorator...            20.0   \n",
       "3565                 business,finance,investing,banking            15.0   \n",
       "...                                                 ...             ...   \n",
       "5506                                         psychology             3.0   \n",
       "5096                                real estate,housing             5.0   \n",
       "853   business,automobiles and vehicles,religion and...             NaN   \n",
       "2846  business,earth and nature,health,environment,w...            16.0   \n",
       "3008  health,health conditions,heart conditions,heal...            16.0   \n",
       "\n",
       "        views  downloads  download_per_view date_created last_updated  \n",
       "2770    723.0       79.0               0.11   12/13/2020   01/04/2021  \n",
       "3646   1498.0      162.0               0.11   11/09/2020   11/09/2020  \n",
       "4845   1265.0      168.0               0.13   09/05/2020   09/05/2020  \n",
       "2790    143.0       21.0               0.15   01/06/2021   01/06/2021  \n",
       "3565    188.0       12.0               0.06   12/19/2020   12/19/2020  \n",
       "...       ...        ...                ...          ...          ...  \n",
       "5506   3008.0      829.0               0.28    2/13/2018    2/13/2018  \n",
       "5096     91.0        3.0               0.03   12/13/2020   12/13/2020  \n",
       "853   45875.0     4086.0               0.09    2/16/2018    2/19/2018  \n",
       "2846    359.0       25.0               0.07   12/24/2020   12/24/2020  \n",
       "3008  70970.0     9707.0               0.14   06/07/2019   06/07/2019  \n",
       "\n",
       "[5717 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a3f4d",
   "metadata": {},
   "source": [
    "Analisis y limpieza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74f3063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5717 entries, 0 to 5716\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   title              5717 non-null   object \n",
      " 1   usability          5717 non-null   float64\n",
      " 2   num_of_files       5384 non-null   float64\n",
      " 3   types_of_files     5450 non-null   object \n",
      " 4   files_size         5651 non-null   object \n",
      " 5   vote_counts        5717 non-null   int64  \n",
      " 6   medal              5717 non-null   object \n",
      " 7   url_reference      5717 non-null   object \n",
      " 8   keywords           5099 non-null   object \n",
      " 9   num_of_columns     3049 non-null   float64\n",
      " 10  views              5716 non-null   float64\n",
      " 11  downloads          5716 non-null   float64\n",
      " 12  download_per_view  5716 non-null   float64\n",
      " 13  date_created       5622 non-null   object \n",
      " 14  last_updated       5622 non-null   object \n",
      "dtypes: float64(6), int64(1), object(8)\n",
      "memory usage: 670.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c097d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 5717, Columnas: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23e415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns] datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Transformar data_created y last_updated a datatime\n",
    "df['date_created'] = pd.to_datetime(df['date_created'])\n",
    "df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "\n",
    "print(df['date_created'].dtype,df['last_updated'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126b5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                   0\n",
      "usability               0\n",
      "num_of_files          333\n",
      "types_of_files        267\n",
      "files_size             66\n",
      "vote_counts             0\n",
      "medal                   0\n",
      "url_reference           0\n",
      "keywords              618\n",
      "num_of_columns       2668\n",
      "views                   1\n",
      "downloads               1\n",
      "download_per_view       1\n",
      "date_created           95\n",
      "last_updated           95\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74e1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos valores que contengan null ya que considero que todos son importantes para el analisis\n",
    "columnas_a_verificar = ['num_of_files', 'files_size', 'num_of_columns','date_created','last_updated']  # Reemplaza con los nombres de tus columnas\n",
    "\n",
    "df_sin_na= df.dropna(subset=columnas_a_verificar)\n",
    "\n",
    "df = df_sin_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0fa0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  usability  \\\n",
      "22                            US Public Food Assistance        9.1   \n",
      "100              CelebFaces Attributes (CelebA) Dataset        7.6   \n",
      "111                                  S&P 500 stock data        7.6   \n",
      "123   GTSRB - German Traffic Sign Recognition Benchmark        8.2   \n",
      "135                         Skin Cancer MNIST: HAM10000        7.1   \n",
      "...                                                 ...        ...   \n",
      "5434                                         caltech256        6.5   \n",
      "5657                       JSRT_ORIGINAL_AND_BONE_MASKS        2.9   \n",
      "5663    Weather Data for Recruit Restaurant Competition        7.1   \n",
      "5667                                     kneeMRIdataset        2.4   \n",
      "5672                              Chest CT Segmentation        6.5   \n",
      "\n",
      "      num_of_files types_of_files files_size  vote_counts     medal  \\\n",
      "22            80.0     other, CSV    703 KB           261      Gold   \n",
      "100       202603.0     other, CSV       1 GB          828      Gold   \n",
      "111          508.0     CSV, other     19 MB           784      Gold   \n",
      "123        51888.0     other, CSV     612 MB          386    Silver   \n",
      "135        10020.0     other, CSV       5 GB          997      Gold   \n",
      "...            ...            ...        ...          ...       ...   \n",
      "5434       30610.0     other, CSV       2 GB            7  No_Medal   \n",
      "5657         488.0     other, CSV       2 GB            4  No_Medal   \n",
      "5663        1670.0            CSV      11 MB           75    Silver   \n",
      "5667         737.0     other, CSV       3 GB           12  No_Medal   \n",
      "5672       33722.0     other, CSV       2 GB            3  No_Medal   \n",
      "\n",
      "                                        url_reference  \\\n",
      "22                         /jpmiller/publicassistance   \n",
      "100                     /jessicali9530/celeba-dataset   \n",
      "111                               /camnugent/sandp500   \n",
      "123   /meowmeowmeowmeowmeow/gtsrb-german-traffic-sign   \n",
      "135                /kmader/skin-cancer-mnist-ham10000   \n",
      "...                                               ...   \n",
      "5434                             /mmoreaux/caltech256   \n",
      "5657           /yoctoman/jsrt-original-and-bone-masks   \n",
      "5663                /huntermcgushion/rrv-weather-data   \n",
      "5667                 /sohaibanwaar1203/kneemridataset   \n",
      "5672                 /polomarco/chest-ct-segmentation   \n",
      "\n",
      "                                               keywords  num_of_columns  \\\n",
      "22    social science,social issues and advocacy,tabu...             6.0   \n",
      "100   business,arts and entertainment,online communi...            41.0   \n",
      "111                          business,finance,investing             7.0   \n",
      "123        online communities,image data,classification             5.0   \n",
      "135         health,image data,multiclass classification             7.0   \n",
      "...                                                 ...             ...   \n",
      "5434                                   computer science             4.0   \n",
      "5657                                                NaN             2.0   \n",
      "5663                   arts and entertainment,geography           111.0   \n",
      "5667                                                NaN            11.0   \n",
      "5672  earth and nature,arts and entertainment,health...             2.0   \n",
      "\n",
      "         views  downloads  download_per_view date_created last_updated  \n",
      "22     60088.0    10467.0               0.17   2018-01-18   2020-08-21  \n",
      "100   300909.0    44636.0               0.15   2018-06-01   2018-06-01  \n",
      "111   230350.0    35108.0               0.15   2017-08-11   2018-02-10  \n",
      "123   139827.0    23371.0               0.17   2018-11-25   2018-11-25  \n",
      "135   321265.0    35095.0               0.11   2018-09-19   2018-09-20  \n",
      "...        ...        ...                ...          ...          ...  \n",
      "5434    7978.0      473.0               0.06   2018-11-21   2018-11-22  \n",
      "5657    1351.0      140.0               0.10   2018-05-08   2018-05-08  \n",
      "5663   16921.0     3928.0               0.23   2017-12-20   2018-01-05  \n",
      "5667    2487.0      223.0               0.09   2019-01-15   2019-01-15  \n",
      "5672    1137.0      129.0               0.11   2020-10-21   2020-10-21  \n",
      "\n",
      "[162 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#Lineas con numero irreal de archivos por dataset\n",
    "columns=df[df['num_of_files'] > 50]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e327d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        title  usability  num_of_files  \\\n",
      "0         COVID-19 World Vaccination Progress       10.0           1.0   \n",
      "2     All Trump's Twitter insults (2015-2021)       10.0           1.0   \n",
      "4                          Temperature change       10.0           2.0   \n",
      "5                CERN electron collision data       10.0           1.0   \n",
      "7                  Wind Power Generation Data       10.0           4.0   \n",
      "...                                       ...        ...           ...   \n",
      "5707                              Pulsar Star        1.8           1.0   \n",
      "5708                  Bollywood Movie Dataset        7.4           3.0   \n",
      "5709                 Blue Book for Bulldozers        2.9           3.0   \n",
      "5715                      Student performance        8.2           2.0   \n",
      "5716                                question2        1.8           1.0   \n",
      "\n",
      "     types_of_files files_size  vote_counts     medal  \\\n",
      "0               CSV     35 KB           173    Silver   \n",
      "2               CSV    581 KB            51    Bronze   \n",
      "4               CSV     778 KB           32    Bronze   \n",
      "5               CSV      6 MB            30    Bronze   \n",
      "7               CSV     245 KB           12    Bronze   \n",
      "...             ...        ...          ...       ...   \n",
      "5707            CSV     771 KB            4  No_Medal   \n",
      "5708            CSV     100 KB           51    Bronze   \n",
      "5709            CSV      10 MB           20  No_Medal   \n",
      "5715            CSV       4 KB           16  No_Medal   \n",
      "5716            CSV     103 KB            2  No_Medal   \n",
      "\n",
      "                                        url_reference  \\\n",
      "0            /gpreda/covid-world-vaccination-progress   \n",
      "2     /ayushggarg/all-trumps-twitter-insults-20152021   \n",
      "4                      /sevgisarac/temperature-change   \n",
      "5           /fedesoriano/cern-electron-collision-data   \n",
      "7                /jorgesandoval/wind-power-generation   \n",
      "...                                               ...   \n",
      "5707                          /shivam1901/pulsar-star   \n",
      "5708                /mitesh58/bollywood-movie-dataset   \n",
      "5709          /farhanreynaldo/blue-book-for-bulldozer   \n",
      "5715                    /hdawkins/student-performance   \n",
      "5716                               /dwit392/question2   \n",
      "\n",
      "                                               keywords  num_of_columns  \\\n",
      "0            health,covid19,public safety,public health            15.0   \n",
      "2     internet,online communities,social science,pol...             5.0   \n",
      "4     earth and nature,health,environment,weather an...            66.0   \n",
      "5     computer science,automobiles and vehicles,scie...            19.0   \n",
      "7                   energy,electricity,renewable energy            97.0   \n",
      "...                                                 ...             ...   \n",
      "5707                                                NaN             9.0   \n",
      "5708  arts and entertainment,movies and tv shows,cla...             8.0   \n",
      "5709                                           business            52.0   \n",
      "5715  education,music,standardized testing,universit...            12.0   \n",
      "5716                                                NaN             4.0   \n",
      "\n",
      "        views  downloads  download_per_view date_created last_updated  \n",
      "0     23364.0     3768.0               0.16   2021-01-12   2021-01-29  \n",
      "2      6703.0      727.0               0.11   2021-01-20   2021-01-20  \n",
      "4      4893.0      798.0               0.16   2020-12-24   2020-12-24  \n",
      "5      1693.0      141.0               0.08   2020-12-25   2020-12-25  \n",
      "7      3128.0      340.0               0.11   2020-12-25   2021-01-07  \n",
      "...       ...        ...                ...          ...          ...  \n",
      "5707    881.0      109.0               0.12   2019-01-26   2019-01-26  \n",
      "5708  28275.0     4289.0               0.15   2018-02-01   2018-02-04  \n",
      "5709   4510.0     1415.0               0.31   2018-02-22   2018-02-22  \n",
      "5715  11711.0     1077.0               0.09   2017-01-25   2017-01-25  \n",
      "5716    105.0       65.0               0.62   2020-10-14   2020-10-14  \n",
      "\n",
      "[2779 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "columns=df[~(df['num_of_files'] > 50)]\n",
    "print(columns)\n",
    "\n",
    "#df con limpieza de num_of_files\n",
    "df = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cfa3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "2       False\n",
      "4       False\n",
      "5       False\n",
      "7       False\n",
      "        ...  \n",
      "5707    False\n",
      "5708    False\n",
      "5709    False\n",
      "5715    False\n",
      "5716    False\n",
      "Name: types_of_files, Length: 2779, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sesa777393\\AppData\\Local\\Temp\\ipykernel_43516\\2546249325.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['types_of_files'].fillna('other', inplace=True)\n",
      "C:\\Users\\sesa777393\\AppData\\Local\\Temp\\ipykernel_43516\\2546249325.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['types_of_files'].fillna('other', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#replazo los nulls de types_of_files por others\n",
    "df['types_of_files'].fillna('other', inplace=True)\n",
    "print(df['types_of_files']=='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1351103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "any_null=(df['types_of_files']=='').sum()\n",
    "print(any_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#elimino duplicados de title\n",
    "duplicates = df['title'].duplicated().any()\n",
    "num_duplicates = df['title'].duplicated().sum()\n",
    "print(num_duplicates)\n",
    "df=df.drop_duplicates(subset=['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5a3f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
